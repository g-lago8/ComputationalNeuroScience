{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts for getting all song lyrics from a given artist\n",
    "\n",
    "import lyricsgenius as lg\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_lyrics = False\n",
    "artist = \"Radiohead\"\n",
    "if download_lyrics:\n",
    "    \n",
    "    load_dotenv()\n",
    "    access_token = os.getenv(\"GENIUS_ACCESS_TOKEN\")\n",
    "\n",
    "    try:\n",
    "        genius = lg.Genius(access_token, skip_non_songs=True,\n",
    "                            excluded_terms=[\"(Remix)\", \"(Live)\", \"Demo\", \"Version\", ], \n",
    "                              remove_section_headers=True, timeout=15, sleep_time=0.5, verbose=True)\n",
    "\n",
    "        artist_songs = genius.search_artist(artist, sort=\"popularity\", get_full_info=False, max_songs=200)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error in getting artist\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_lyrics:    \n",
    "    with open(f'lyrics_{artist}.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "        for song in artist_songs.songs:\n",
    "            f.write(song.lyrics)\n",
    "            f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'lyrics/lyrics_{artist}.txt', \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs =lyrics.split(\"Lyrics\")\n",
    "songs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "We basically remove all the useless data, like contributors and translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each line, put the last \\n and following text in a separate line\n",
    "\n",
    "for i, song in enumerate(songs):\n",
    "    # identify the last \\n\n",
    "    last_n = song.rfind(\"\\n\")\n",
    "    if last_n!=-1:\n",
    "        # split the song\n",
    "        songs[i] = song[:last_n] \n",
    "        songs.insert(i+1, song[last_n+1:])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(songs))\n",
    "# remove empty songs\n",
    "songs = [song for song in songs if song.strip()!=\"\"]\n",
    "print(len(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "songs = [songs[i]+ songs[i+1] for i in range(0, len(songs), 2)]\n",
    "print(len(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete first line of each song\n",
    "songs = [song[song.find(\"\\n\")+1:] for song in songs]\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = [song for song in songs if song != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(songs)):\n",
    "\n",
    "    # if song ends with Embed\n",
    "    #cancel Embed and eventual numbers before it\n",
    "    songs[i] = songs[i][:songs[i].rfind(\"Embed\")]\n",
    "    while songs[i][-1].isnumeric():\n",
    "        songs[i] = songs[i][:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the characters\n",
    "chars = list(set(\"\".join(songs)))\n",
    "char_to_index = {c:i for i, c in enumerate(chars)}\n",
    "index_to_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add two special characters for start and end of song\n",
    "if \"<\" not in chars:\n",
    "    print(\"Adding <\")\n",
    "    chars.append(\"<\")\n",
    "\n",
    "if \">\" not in chars:\n",
    "    print(\"Adding >\")\n",
    "    chars.append(\">\")\n",
    "char_to_index['<'] = len(chars)-2\n",
    "char_to_index['>'] = len(chars)-1\n",
    "\n",
    "index_to_char[len(chars)-2] = \"<\"\n",
    "index_to_char[len(chars)-1] = \">\"\n",
    "songs = [f\"<{song}>\" for song in songs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_songs = [[char_to_index[c] for c in song] for song in songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = [song[:-1] for song in encoded_songs]\n",
    "output_sequences = [song[1:] for song in encoded_songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the sequences\n",
    "dim_one_hot = len(chars)\n",
    "input_sequences = [torch.tensor(seq).long() for seq in input_sequences]\n",
    "output_sequences = [torch.tensor(seq).long() for seq in output_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, input_sequences, output_sequences):\n",
    "        self.input_sequences = input_sequences\n",
    "        self.output_sequences = output_sequences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_sequences[idx], self.output_sequences[idx], len(self.input_sequences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_sequences = [item[0] for item in batch]\n",
    "    output_sequences = [item[1] for item in batch]\n",
    "    lengths= [item[2] for item in batch]\n",
    "    input_sequences = nn.utils.rnn.pad_sequence(input_sequences, batch_first=True)\n",
    "    output_sequences = nn.utils.rnn.pad_sequence(output_sequences, batch_first=True)\n",
    "    return input_sequences, output_sequences, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(LyricsDataset(input_sequences, output_sequences), batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# create the model\n",
    "\n",
    "class LyricsModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, n_layers_lstm=1, dropout=0.):\n",
    "        super(LyricsModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers_lstm = n_layers_lstm\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_dim, batch_first=True, num_layers=n_layers_lstm, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.softmax = nn.functional.softmax\n",
    "        \n",
    "    def forward(self, x, hidden_states =None):\n",
    "        x = self.embed(x)\n",
    "        x, [h, c] = self.lstm(x, hidden_states)\n",
    "       # x, _ = pad_packed_sequence(x, batch_first=True)\n",
    "        x = self.fc(x)\n",
    "        return x, [h,c]\n",
    "    \n",
    "    def generate_text(self, max_length, temperature):\n",
    "        generated = \"<\"\n",
    "        last_char = generated\n",
    "        h = torch.zeros(self.n_layers_lstm, 1, self.hidden_dim, dtype=torch.float32)\n",
    "        c = torch.zeros(self.n_layers_lstm, 1, self.hidden_dim, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            for i in range(max_length):\n",
    "                x = torch.tensor(char_to_index[last_char])\n",
    "                x = x.unsqueeze(0).unsqueeze(0)\n",
    "                x, [h, c] = self.forward(x, [h, c])\n",
    "                x = torch.divide(x, temperature)\n",
    "                x = self.softmax(x, dim=2)\n",
    "                # draw a sample from x\n",
    "                last_char = torch.distributions.Categorical(x).sample()\n",
    "                last_char = index_to_char[last_char.item()]\n",
    "                generated += last_char\n",
    "                if last_char == \">\":\n",
    "                    break \n",
    "        print(generated)\n",
    "        return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LyricsModel(dim_one_hot, 256, 256, n_layers_lstm=2, dropout=0.5)\n",
    "dataset=LyricsDataset(input_sequences, output_sequences)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "batch_size =1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:44<?, ?it/s, running_loss=2.4540529251098633, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 2.4540529251098633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:47<03:10, 47.68s/it, running_loss=2.4540529251098633, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<In a me sand and me the wat bild of all warl some hough your sut wand the fall the we me come\n",
      "\n",
      "I dore\n",
      "I the be cheac you to are sore stor in the waped be in the we hing and of the to beand me\n",
      "And in the son the the been of thee the can the carl your you fat me come warl the me bam tor in this noing sonone be on the hard\n",
      "I wam me youn saald I kard an it me dorn the wall thad ther not the marry shere heall wins the beer at the car the sel the dams fee stare\n",
      "I beand me the the cout the ther med bery you in the card\n",
      "I dowrow wan the bea got sind\n",
      "I wall ald son't a down beace are cand it seare\n",
      "\n",
      "You wan the the to core\n",
      "ne\n",
      "\n",
      "I dam hap the the list the ill hear your beand\n",
      "I sto back me the the to mere to >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:28<03:10, 47.68s/it, running_loss=2.0662784576416016, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 2.0662784576416016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:30<02:14, 44.89s/it, running_loss=1.9074400663375854, batch=1/183]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<I to sorn\n",
      "\n",
      "Thet and mot in all the hears it me a me fround\n",
      "We not the leal\n",
      "Thes a me the the supter to to warns\n",
      "I'm lown\n",
      "\n",
      "Dour be to best a like your to me and me the sundend\n",
      "If to want a want a wall\n",
      "Now don't to got me out\n",
      "I got be the in in a don't turt to gond I wart frong\n",
      "\n",
      "I want your sell\n",
      "\n",
      "Gowe me cand\n",
      "\n",
      "But the bet on to stares\n",
      "You gow lay me are re your so sonntres my your son't can't hake to sme cand on a are the not it we are your and leate the let be thing mones\n",
      "You >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:09<02:14, 44.89s/it, running_loss=1.9281063079833984, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss = 1.9281063079833984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:13<01:27, 43.80s/it, running_loss=1.9281063079833984, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "In clain it for wants I start the live\n",
      "\n",
      "One warks don't got to you \n",
      "And what the let a do fore\n",
      "If wall to me be the do come\n",
      "The can the ever on the should I was all is feel the bease of you're to got the cald verong to be to all me the pean\n",
      "The hastle the real the the reall\n",
      "\n",
      "It's no blow in the sare\n",
      "I don't to come be from the fish you what to will me\n",
      "I wast the dean the shase\n",
      "So the star alallt of plow\n",
      "A me to come\n",
      "I dorn cans in of the come\n",
      "\n",
      "Where was you don't no be and the to stre all stishers all likes\n",
      "And I'm me back\n",
      "\n",
      "And the fase to hom for trey like firns and finet be bet a frack\n",
      "\n",
      "In the wan thing up me\n",
      "I was in the be leats the sing the whon't to strins\n",
      "\n",
      "The so care a not strees and sill it the kear\n",
      "I want the stor go a no no the cand\n",
      "A linet the can't for bave the came the sinet no stat no a go she go come\n",
      "\n",
      "So no the down as a wark but your beall\n",
      "And to me the this chull the shashing the do no no will the stand the be of you, crack rake are the home\n",
      "\n",
      "Kell no no surns\n",
      "I'm the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:50<01:27, 43.80s/it, running_loss=1.8303911685943604, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss = 1.8303911685943604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:51<00:41, 41.68s/it, running_loss=1.6678546667099, batch=1/183]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<I'm hore an into hears\n",
      "And chan't reart\n",
      "It want you stis in anlate\n",
      "I am you song think on a will my arm come\n",
      "If word the somest wanting the spece me the don't leal the gontrome\n",
      "I cont won't what come the come the crike\n",
      "You >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:30<00:41, 41.68s/it, running_loss=1.7521202564239502, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss = 1.7521202564239502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "I can a look the go are to here\n",
      "\n",
      "I contright\n",
      "\n",
      "I find one are are wack\n",
      "You >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 5\n",
    "def train_model(model, dataloader, optimizer, n_epochs):\n",
    "    train_bar =tqdm(range(n_epochs),leave=False )\n",
    "    for epoch in train_bar:\n",
    "        running_loss =0\n",
    "        n_seen=0\n",
    "        for i, (x, y, lens) in enumerate(dataloader):   \n",
    "            optimizer.zero_grad()\n",
    "            y_pred, _ = model(x)\n",
    "            loss = nn.functional.cross_entropy(y_pred.permute(0,2,1), y.data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss * batch_size\n",
    "            n_seen += batch_size\n",
    "            running_loss +=loss\n",
    "            train_bar.set_postfix({'running_loss': f'{running_loss/n_seen}', 'batch':f'{i+1}/{len(dataloader)}'})\n",
    "        print(f\"Epoch {epoch}, loss = {running_loss/n_seen}\")\n",
    "        model.generate_text(max_length =1000, temperature = 0.5)\n",
    "\n",
    "train_model(model, dataloader, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:42<?, ?it/s, running_loss=1.6185073852539062, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 1.6185073852539062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:46<01:31, 45.88s/it, running_loss=1.5644395351409912, batch=1/183]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<I can't hurt\n",
      "We're the need in the free and nothing the runners\n",
      "Up the me to the happer that your see in the see and the really the massed\n",
      "The the read and the fut the seeds and the beat up the spin\n",
      "Into hearms hurt flace\n",
      "\n",
      "I will never home in the stindrops\n",
      "You \n",
      "I was the let my sentic, no, I can't leave the the flain\n",
      "\n",
      "In you car me\n",
      "It am the back in the need in a changers\n",
      "When you're with me heads\n",
      "\n",
      "When in call, the the the pird on a morn\n",
      "I hand of the child of the read the wind, the put the treaking and the live\n",
      "\n",
      "The they see a day in the pack of the chome\n",
      "I get me on the the friend the stop the man\n",
      "I hurt the start to ears the the pot the flace\n",
      "And heards and white in the know the walk\n",
      "\n",
      "I want you can't shee down and like here\n",
      "But the know when I get the really me on\n",
      "\n",
      "I wink the start be the fritter a way\n",
      "I chollate\n",
      "\n",
      "I really son't get the think it white I want and the care\n",
      "I'm not crazy cars\n",
      "When you such a spening of the want\n",
      "When the hand and the want the the klood\n",
      "I messing and \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [01:31<01:31, 45.88s/it, running_loss=1.5416948795318604, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 1.5416948795318604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:35<00:48, 48.11s/it, running_loss=1.5416948795318604, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "I want the see drise of coming\n",
      "\n",
      "I start to me the skilled to betters\n",
      "(Why we love the see strake of the ready on\n",
      "\n",
      "I will me when you've give your light\n",
      "I want the sould the moon\n",
      "Little don't leave be walking on the hore\n",
      "\n",
      "One when you sick the mound\n",
      "\n",
      "I can't to the end, we all where\n",
      "You \n",
      "I want the walk the strick of the better me\n",
      "\n",
      "Lut this is and into the moon\n",
      "You want you the really say the starts in the should from the shack\n",
      "I just to the cromesses\n",
      "The hast you surpries\n",
      "We are your should the starts on the string on the boot\n",
      "How want the love me want\n",
      "We talking of the next to the world\n",
      "\n",
      "I think you start the see the stry shad\n",
      "I get you the blood\n",
      "When you've been better mes\n",
      "Are you spay be the craming and the tart\n",
      "\n",
      "I am not that you say that the some\n",
      "You \n",
      "They want the freest the back out\n",
      "The waits for your spared and never going to shear\n",
      "\n",
      "Don't leave you they hears\n",
      "\n",
      "I want you don't leave the cars\n",
      "I want the world, shines on the see is the still\n",
      "\n",
      "I will dears off all the shildrors\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [02:23<00:48, 48.11s/it, running_loss=1.4725643396377563, batch=183/183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss = 1.4725643396377563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<I want the really come\n",
      "And me out you alive\n",
      "I was the end you can a line\n",
      "Where are you can a lough a lost me\n",
      "And I will be tree in a line\n",
      "And you can a burns in the glad in a polies\n",
      "The best we hand of the crould\n",
      "The can a well of the lone\n",
      "I was seep you to see\n",
      "\n",
      "I don't hurt you can the best\n",
      "When you go the bood baby\n",
      "I want you can see you wall\n",
      "I'm a want the botter\n",
      "I want me from the back\n",
      "I want me me down\n",
      "There's a give anywhere I can something up things\n",
      "I'm not a spectre be not good the look around\n",
      "There'll be gonna do in the burns\n",
      "The end you can the said out the be around\n",
      "\n",
      "I will here you can\n",
      "\n",
      "Letter me alarms\n",
      "From the lift the earth\n",
      "The raindropses and the light\n",
      "I supplies, this us you don't really like now coming a burns\n",
      "There'll do stupprops\n",
      "And I start a call the can a life\n",
      "I lies and the lone in your hide\n",
      "I was the earth a could you can the strison\n",
      "You \n",
      "I was should be the world\n",
      "The light is an a triend\n",
      "I sust the born by in a line\n",
      "Now the paris the fall of the sing out\n",
      "The b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, optimizer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_seed(model, seed, temperature, max_length=1000):\n",
    "    generated = seed\n",
    "    seed = [char_to_index[c] for c in seed]\n",
    "    seed = torch.tensor(seed).long()\n",
    "    seed = seed.unsqueeze(0)\n",
    "    model.eval()\n",
    "    logits, [h, c] = model(seed)\n",
    "    logits = torch.divide(logits, temperature)\n",
    "    logits=logits[:, -1,:]\n",
    "    softmax_values = model.softmax(logits, dim=1)\n",
    "\n",
    "    last_char = torch.distributions.Categorical(softmax_values).sample()\n",
    "    last_char = index_to_char[last_char.item()]\n",
    "    generated += last_char\n",
    "    for i in range(max_length):\n",
    "        x = torch.tensor(char_to_index[last_char])\n",
    "        x = x.unsqueeze(0).unsqueeze(0)\n",
    "        x, [h, c] = model.forward(x, [h, c])\n",
    "        x = torch.divide(x, temperature)\n",
    "        x = model.softmax(x, dim=2)\n",
    "        # draw a sample from x\n",
    "        last_char = torch.distributions.Categorical(x).sample()\n",
    "        last_char = index_to_char[last_char.item()]\n",
    "        generated += last_char\n",
    "        if last_char == \">\":\n",
    "            break\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.1\n",
      "Karma Police, arrest this man\n",
      "I want the be around\n",
      "I want the be the paranough\n",
      "The raindrops and the best you can\n",
      "I want the cars and the best you can\n",
      "I want the car are a line\n",
      "I will be the best you can a line\n",
      "\n",
      "I want the cars and the light\n",
      "The really care the best you can a light\n",
      "The best you can the be around\n",
      "I will be the best you can the be the best\n",
      "I want the be the say the see\n",
      "\n",
      "I will be the best you can the best\n",
      "I want the be around\n",
      "\n",
      "I will see you can the be the say the see\n",
      "\n",
      "I will be the best you can a light\n",
      "The raindrops and the really see it coming and the see\n",
      "\n",
      "I will be the stre all the stres\n",
      "I will be the strient the say the say the see\n",
      "\n",
      "I will be the best you can a bullet me\n",
      "I want the cars and the cars\n",
      "The raindrops and the raindrops\n",
      "The best you can a bullet the see\n",
      "\n",
      "I want the be the wards\n",
      "The was something out the say the best\n",
      "I want the cars and spectre\n",
      "I will be a line\n",
      "\n",
      "I want the be around\n",
      "I will be the stre along\n",
      "The care a bullet the say the say the best\n",
      "I want the best you can a line\n",
      "I want\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Temperature = 0.5\n",
      "Karma Police, arrest this man out\n",
      "No little do you can\n",
      "And thell will me out in the coming\n",
      "There's a burn a really leave lest\n",
      "I was such a lone\n",
      "I something in a little out of me\n",
      "Before your hautiout you the the born\n",
      "I'm a carbolasses\n",
      "And you something up the stren\n",
      "The ring on the dost\n",
      "I can the best you can\n",
      "The mornesself all the past\n",
      "They don't you can see is an all suppon\n",
      "\n",
      "The wish I want the care\n",
      "I got the straindrops, you up\n",
      "I can't hurt mors out be the poison\n",
      "The rest a mouth as something out a think I don't same a break the come\n",
      "The beauth a becould be the bottle is an alive\n",
      "And you can the peather\n",
      "The will me will coming all something back\n",
      "\n",
      "I was not the rest you\n",
      "\n",
      "The look you can the put of my leave\n",
      "\n",
      "I am the want the stroon\n",
      "And you can the best me in a get the light\n",
      "The good the mornas soul your lies\n",
      "I was man be around\n",
      "Where you can a babout\n",
      "I want the want out\n",
      "There'll could no not a lies\n",
      "I want the full a boat be come\n",
      "I am the something around\n",
      "I don't are spit the seep\n",
      "The moors are here\n",
      "Fill me on the \n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Temperature = 0.9\n",
      "Karma Police, arrest this man selprole is\n",
      "It's retal though the belong it can\n",
      "The liftued and is you good low\n",
      "And I can the buck amry's something\n",
      "Even up me all\n",
      "Full me save a me\n",
      "Stirdions all murts from smalk to speciaking criess\n",
      "\n",
      "I want you be trong\n",
      "Before you from I could be love on be your but stulls\n",
      "\n",
      "When you with myself the best you are suck your moother are all be back\n",
      "Will you chow down, treeth\n",
      "Threassyon, I'll way nothen the cars\n",
      "\n",
      "\n",
      "I am mone Jame to illy get over tasho\n",
      "Denders, but veaking lit\n",
      "Unlight will be tumpirs\n",
      "All the pace no harmrieses\n",
      "And you can sursept the peatay\n",
      "And reep the surut baugh out>\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0.1, 0.5, 0.9]\n",
    "for temp in temperatures:\n",
    "    print(f\"Temperature = {temp}\")\n",
    "    generate_text_from_seed(model, \"Karma Police, arrest this man\", temp)\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Karma Police, arrest this man out\n",
    "\n",
    "No little do you can\n",
    "\n",
    "And thell will me out in the coming\n",
    "\n",
    "There's a burn a really leave lest\n",
    "\n",
    "I was such a lone\n",
    "\n",
    "I something in a little out of me\n",
    "\n",
    "Before your hautiout you the the born\n",
    "\n",
    "I'm a carbolasses\"\n",
    "\n",
    "Pure Radiohead poetry!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
